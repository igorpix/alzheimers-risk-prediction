{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üß™ Etapa INICIAL: Abrir e visualizar os dados"
      ],
      "metadata": {
        "id": "hSnyamkGajTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o novo dataset\n",
        "path = '/content/alzheimers_disease_data.csv'  # Caminho do seu arquivo\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# Verificar as primeiras linhas\n",
        "print(df.head())\n",
        "\n",
        "# Verificar informa√ß√µes gerais\n",
        "print(df.info())\n",
        "\n",
        "# Verificar se h√° valores ausentes\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsXGT-FhRKkk",
        "outputId": "7e8f3ec9-2e97-491c-a1d9-9a35b1b7fefd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
            "0       4751   73       0          0               2  22.927749        0   \n",
            "1       4752   89       0          0               0  26.827681        0   \n",
            "2       4753   73       0          3               1  17.795882        0   \n",
            "3       4754   74       1          0               1  33.800817        1   \n",
            "4       4755   89       0          0               0  20.716974        0   \n",
            "\n",
            "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
            "0           13.297218          6.327112     1.347214  ...                 0   \n",
            "1            4.542524          7.619885     0.518767  ...                 0   \n",
            "2           19.555085          7.844988     1.826335  ...                 0   \n",
            "3           12.209266          8.428001     7.435604  ...                 0   \n",
            "4           18.454356          6.310461     0.795498  ...                 0   \n",
            "\n",
            "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
            "0                   0  1.725883          0               0   \n",
            "1                   0  2.592424          0               0   \n",
            "2                   0  7.119548          0               1   \n",
            "3                   1  6.481226          0               0   \n",
            "4                   0  0.014691          0               0   \n",
            "\n",
            "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
            "0                   0                          1              0          0   \n",
            "1                   0                          0              1          0   \n",
            "2                   0                          1              0          0   \n",
            "3                   0                          0              0          0   \n",
            "4                   1                          1              0          0   \n",
            "\n",
            "   DoctorInCharge  \n",
            "0       XXXConfid  \n",
            "1       XXXConfid  \n",
            "2       XXXConfid  \n",
            "3       XXXConfid  \n",
            "4       XXXConfid  \n",
            "\n",
            "[5 rows x 35 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2149 entries, 0 to 2148\n",
            "Data columns (total 35 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   PatientID                  2149 non-null   int64  \n",
            " 1   Age                        2149 non-null   int64  \n",
            " 2   Gender                     2149 non-null   int64  \n",
            " 3   Ethnicity                  2149 non-null   int64  \n",
            " 4   EducationLevel             2149 non-null   int64  \n",
            " 5   BMI                        2149 non-null   float64\n",
            " 6   Smoking                    2149 non-null   int64  \n",
            " 7   AlcoholConsumption         2149 non-null   float64\n",
            " 8   PhysicalActivity           2149 non-null   float64\n",
            " 9   DietQuality                2149 non-null   float64\n",
            " 10  SleepQuality               2149 non-null   float64\n",
            " 11  FamilyHistoryAlzheimers    2149 non-null   int64  \n",
            " 12  CardiovascularDisease      2149 non-null   int64  \n",
            " 13  Diabetes                   2149 non-null   int64  \n",
            " 14  Depression                 2149 non-null   int64  \n",
            " 15  HeadInjury                 2149 non-null   int64  \n",
            " 16  Hypertension               2149 non-null   int64  \n",
            " 17  SystolicBP                 2149 non-null   int64  \n",
            " 18  DiastolicBP                2149 non-null   int64  \n",
            " 19  CholesterolTotal           2149 non-null   float64\n",
            " 20  CholesterolLDL             2149 non-null   float64\n",
            " 21  CholesterolHDL             2149 non-null   float64\n",
            " 22  CholesterolTriglycerides   2149 non-null   float64\n",
            " 23  MMSE                       2149 non-null   float64\n",
            " 24  FunctionalAssessment       2149 non-null   float64\n",
            " 25  MemoryComplaints           2149 non-null   int64  \n",
            " 26  BehavioralProblems         2149 non-null   int64  \n",
            " 27  ADL                        2149 non-null   float64\n",
            " 28  Confusion                  2149 non-null   int64  \n",
            " 29  Disorientation             2149 non-null   int64  \n",
            " 30  PersonalityChanges         2149 non-null   int64  \n",
            " 31  DifficultyCompletingTasks  2149 non-null   int64  \n",
            " 32  Forgetfulness              2149 non-null   int64  \n",
            " 33  Diagnosis                  2149 non-null   int64  \n",
            " 34  DoctorInCharge             2149 non-null   object \n",
            "dtypes: float64(12), int64(22), object(1)\n",
            "memory usage: 587.7+ KB\n",
            "None\n",
            "PatientID                    0\n",
            "Age                          0\n",
            "Gender                       0\n",
            "Ethnicity                    0\n",
            "EducationLevel               0\n",
            "BMI                          0\n",
            "Smoking                      0\n",
            "AlcoholConsumption           0\n",
            "PhysicalActivity             0\n",
            "DietQuality                  0\n",
            "SleepQuality                 0\n",
            "FamilyHistoryAlzheimers      0\n",
            "CardiovascularDisease        0\n",
            "Diabetes                     0\n",
            "Depression                   0\n",
            "HeadInjury                   0\n",
            "Hypertension                 0\n",
            "SystolicBP                   0\n",
            "DiastolicBP                  0\n",
            "CholesterolTotal             0\n",
            "CholesterolLDL               0\n",
            "CholesterolHDL               0\n",
            "CholesterolTriglycerides     0\n",
            "MMSE                         0\n",
            "FunctionalAssessment         0\n",
            "MemoryComplaints             0\n",
            "BehavioralProblems           0\n",
            "ADL                          0\n",
            "Confusion                    0\n",
            "Disorientation               0\n",
            "PersonalityChanges           0\n",
            "DifficultyCompletingTasks    0\n",
            "Forgetfulness                0\n",
            "Diagnosis                    0\n",
            "DoctorInCharge               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìã An√°lise do novo dataset\n",
        "‚úÖ 2149 registros (linhas)\n",
        "\n",
        "‚úÖ 35 colunas (atributos)\n",
        "\n",
        "‚úÖ Nenhum valor nulo (√≥timo, n√£o precisa se preocupar com limpeza nesse ponto)\n",
        "\n",
        "üéØ A vari√°vel alvo que queremos prever √© Diagnosis:\n",
        "\n",
        "Provavelmente:\n",
        "\n",
        "0 = N√£o tem Alzheimer\n",
        "\n",
        "1 = Tem Alzheimer\n",
        "\n",
        "üóÇÔ∏è As colunas s√£o majoritariamente:\n",
        "\n",
        "Num√©ricas (int64 e float64)\n",
        "\n",
        "1 coluna textual: DoctorInCharge (object) ‚Üí vamos ignorar essa coluna (n√£o tem utilidade para o modelo)\n",
        "\n",
        "üéõÔ∏è Algumas vari√°veis s√£o sim/n√£o (tipo Smoking, Diabetes, FamilyHistoryAlzheimers...)"
      ],
      "metadata": {
        "id": "29q9WGQyS-a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖEtapa 2: prepararando os dados para o *modelo*"
      ],
      "metadata": {
        "id": "TMEtP0HsSWge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover colunas in√∫teis\n",
        "df = df.drop(columns=[\"PatientID\", \"DoctorInCharge\"]) #Colunas que n√£o ajuda a prever Alzheimer\n",
        "\n",
        "# Separar entrada e alvo\n",
        "target = \"Diagnosis\"  #define que o que queremos prever √© a coluna Diagnosis\n",
        "X = df.drop(columns=[target])  # cria um novo dataframe X com todas as colunas menos a Diagnosis (ou seja, as vari√°veis de entrada).\n",
        "y = df[target]  #separa a coluna Diagnosis como o r√≥tulo/alvo (0 = n√£o tem Alzheimer, 1 = tem Alzheimer).\n"
      ],
      "metadata": {
        "id": "5Tf0ZMeKTZRK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üî¢ Etapa 3. Separar em treino e teste\n",
        "\n",
        "##üß† Por que separamos em treino e teste?\n",
        "Porque queremos saber se nosso modelo realmente aprendeu a generalizar, ou s√≥ decorou os dados que viu.\n",
        "\n",
        "Imagine o seguinte:\n",
        "\n",
        "Voc√™ d√° um monte de exerc√≠cios pro seu aluno estudar...\n",
        "Depois, aplica uma prova com os mesmos exerc√≠cios.\n",
        "Ele tira 10.\n",
        "Mas... ser√° que ele aprendeu ou s√≥ decorou?\n",
        "\n",
        "√â isso que acontece se a gente testa o modelo nos mesmos dados que usou pra treinar: ele pode ir bem s√≥ porque j√° viu as respostas.\n",
        "\n",
        "##‚úÖ Separar treino e teste permite:\n",
        "Treinar o modelo em um peda√ßo dos dados\n",
        "\n",
        "Avaliar o desempenho em dados \"novos\" que ele nunca viu\n",
        "\n",
        "Isso mostra se o modelo realmente aprendeu algo √∫til e consegue generalizar\n",
        "\n",
        "##üìä Exemplo simples:\n",
        "Se voc√™ tem 1.000 pacientes:\n",
        "\n",
        "800 v√£o pro treinamento (X_train, y_train)\n",
        "\n",
        "200 v√£o pro teste (X_test, y_test)\n",
        "\n",
        "Voc√™ treina o modelo s√≥ com os 800\n",
        "E avalia com os 200 que ele nunca viu\n",
        "\n",
        "##üß™ Por que isso importa?\n",
        "Se o modelo for √≥timo no treino, mas ruim no teste, isso indica:\n",
        "\n",
        "Ele decorou os dados (overfitting)\n",
        "\n",
        "N√£o consegue generalizar pra novos casos\n",
        "\n",
        "##üìå random_state=42: o que √© isso?\n",
        "Isso √© s√≥ uma ‚Äúsemente aleat√≥ria‚Äù ‚Äî serve pra que a separa√ß√£o aconte√ßa da mesma forma toda vez que voc√™ rodar o c√≥digo.\n",
        "Isso garante que seus resultados sejam reprodut√≠veis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GJPQK7KRTqYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,              # X = features, y = r√≥tulo (alvo)\n",
        "    test_size=0.2,     # 20% dos dados v√£o pro teste\n",
        "    random_state=42    # pra garantir que a divis√£o seja sempre igual (reprodut√≠vel)\n",
        ")"
      ],
      "metadata": {
        "id": "C62AoBUzTq6y"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Agora com os dados prontos (codificados, divididos e organizados), a gente pode seguir para o treinamento com PyTorch.\n",
        "\n",
        "#üî¢ Etapa 4: Normalizar os dados\n",
        "##A normaliza√ß√£o ajuda bastante o modelo a convergir. Vamos aplicar a padroniza√ß√£o (Z-score):\n",
        "\n",
        "##üéØ O que √© normaliza√ß√£o/padroniza√ß√£o de dados?\n",
        "√â o processo de transformar os valores num√©ricos para que fiquem na mesma escala.\n",
        "\n",
        "##üìâ Exemplo:\n",
        "Suponha que voc√™ tem essas duas features:\n",
        "\n",
        "Idade\t                      50 a 90 anos\n",
        "\n",
        "N√≠vel de estresse          \t0 a 10\n",
        "\n",
        "Sem normaliza√ß√£o:\n",
        "\n",
        "A idade domina a entrada (valores grandes)\n",
        "\n",
        "O modelo d√° mais import√¢ncia pra ela s√≥ por causa da escala, n√£o necessariamente porque ela √© mais relevante.\n",
        "\n",
        "##üß† Por que isso atrapalha?\n",
        "Modelos como a regress√£o log√≠stica e redes neurais usam gradientes e dist√¢ncias internas (em espa√ßos vetoriais). Se uma vari√°vel tem valores muito maiores que as outras, ela pode:\n",
        "\n",
        "\"Puxar\" o gradiente todo pra ela\n",
        "\n",
        "Causar converg√™ncia lenta\n",
        "\n",
        "Gerar instabilidade num√©rica\n",
        "\n",
        "Fazer o modelo aprender \"torto\"\n",
        "\n",
        ".\n",
        "\n",
        "##üßÆ O que √© Z-score (padroniza√ß√£o)?\n",
        "Z-score √© uma forma de transformar qualquer n√∫mero em uma escala padr√£o, baseada na dist√¢ncia que ele est√° da m√©dia, em unidades de desvio padr√£o.\n",
        "\n",
        "##üìä Exemplo da vida real:\n",
        "Imagine que temos as idades de 5 pessoas: [20, 25, 30, 35, 40]\n",
        "\n",
        "A m√©dia (Œº) √© 30, e o desvio padr√£o (œÉ) √© cerca de 7.07\n",
        "\n",
        "Agora vamos calcular o Z-score da idade 40:\n",
        "\n",
        "(40-30)/7.03 = 1.41\n",
        "\n",
        "Ou seja:\n",
        "\n",
        "A idade 40 est√° 1.41 desvios padr√£o acima da m√©dia.\n",
        "\n",
        "##üß† Uma analogia simples:\n",
        "Pensa que voc√™ tem notas de alunos em disciplinas diferentes:\n",
        "\n",
        "Matem√°tica: 0 a 100\n",
        "\n",
        "Educa√ß√£o F√≠sica: 0 a 10\n",
        "\n",
        "M√∫sica: 0 a 5\n",
        "\n",
        "Como comparar o desempenho em disciplinas com escalas diferentes? N√£o d√°, n√©?\n",
        "\n",
        "Mas se voc√™ transformar todas em Z-score, a√≠ sim voc√™ consegue saber:\n",
        "\n",
        "Em qual mat√©ria a pessoa est√° mais acima ou abaixo da m√©dia\n",
        "\n",
        "Mesmo que as escalas sejam diferentes!\n",
        "\n",
        "##‚ö†Ô∏è E se n√£o padronizar?\n",
        "O modelo vai achar que \"idade\" √© mais importante s√≥ porque tem n√∫meros maiores, por exemplo:\n",
        "\n",
        "Idade: 70\n",
        "\n",
        "Estresse: 3\n",
        "\n",
        "Sem padroniza√ß√£o, parece que \"idade\" importa mais ‚Äî mas isso pode ser falso."
      ],
      "metadata": {
        "id": "OMPABTFQU5F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train) #Calcula a m√©dia e desvio padr√£o e Aplica a padroniza√ß√£o no X_train\n",
        "X_test = scaler.transform(X_test) #Usa a mesma m√©dia e desvio do treino para transformar o teste\n"
      ],
      "metadata": {
        "id": "gElf4RuKU9mb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîÅ Etapa 5: Transformar em Tensores PyTorch\n",
        "Agora transformamos os dados em tensores para usar no modelo:\n",
        "\n",
        "##üì¶ Resumo da miss√£o aqui:\n",
        "O objetivo dessa etapa √© pegar os dados do pandas e deixar no formato que o PyTorch entende, que s√£o os tensores.\n",
        "Depois, a gente organiza esses dados em batches (lotes), pra alimentar o modelo aos poucos durante o treinamento.\n",
        "\n",
        "##üß± 1. O que s√£o Tensores?\n",
        "Um tensor √© basicamente a forma como o PyTorch representa os dados. Ele √© parecido com:\n",
        "\n",
        "Vetor ‚Üí 1D\n",
        "\n",
        "Matriz ‚Üí 2D\n",
        "\n",
        "Tensor ‚Üí pode ser 3D, 4D, etc.\n",
        "\n",
        "##üß† Analogia simples:\n",
        "Imagina que voc√™ tem uma pilha de cartas com perguntas e respostas (se a pessoa tem Alzheimer ou n√£o).\n",
        "O TensorDataset junta a pergunta e a resposta.\n",
        "O DataLoader pega 32 cartas por vez e entrega pro modelo estudar.\n",
        "\n",
        "##üßÆ Imagine esses dados simples:\n",
        "Suponha que voc√™ tem 3 pacientes com 2 atributos cada (ex: idade e IMC) e um diagn√≥stico (y) de Alzheimer:\n",
        "\n",
        "       X = [[65, 25.0],\n",
        "            [70, 30.5],\n",
        "            [80, 28.1]]\n",
        "\n",
        "        y = [0, 1, 1]  # 0 = sem Alzheimer, 1 = com Alzheimer\n",
        "\n",
        "üîπ Antes do unsqueeze\n",
        "y √© um vetor 1D: [0, 1, 1]\n",
        "O modelo espera algo assim (2D): [[0],\n",
        " [1],\n",
        " [1]]\n",
        "\n",
        "√â aqui que entra: y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "üîπ Resultado da transforma√ß√£o\n",
        "\n",
        "        y_tensor =\n",
        "        tensor([[0.],\n",
        "                [1.],\n",
        "                [1.]])\n",
        "\n",
        "üîπ Criando o TensorDataset\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "Isso transforma os dados em pares:\n",
        "\n",
        "         [(X[0], y[0]),\n",
        "         (X[1], y[1]),\n",
        "         (X[2], y[2])]\n",
        "\n",
        " üîÑ Agora o DataLoader em a√ß√£o\n",
        "\n",
        " loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
        "\n",
        " O loader vai entregar os dados assim:\n",
        "\n",
        "     Primeira rodada:\n",
        "     X = [[65.0, 25.0],\n",
        "          [70.0, 30.5]]\n",
        "\n",
        "     y = [[0.],\n",
        "          [1.]]\n",
        "\n",
        "     Segunda rodada:\n",
        "     X = [[80.0, 28.1]]\n",
        "     y = [[1.]]\n",
        "\n",
        "\n",
        "##üß† Benef√≠cios:\n",
        "‚úÖ Evita estourar mem√≥ria (quando o dataset √© grande)\n",
        "‚úÖ Deixa o treinamento mais est√°vel\n",
        "‚úÖ Permite embaralhar os dados a cada √©poca ‚Üí ajuda o modelo a aprender melhor\n",
        "\n"
      ],
      "metadata": {
        "id": "lZcONNEYVdFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Converter para tensores\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)  #torch.tensor(...)\tConverte arrays NumPy em tensores\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) #.unsqueeze(1)\tTransforma vetor em coluna (pra bater com o que o modelo espera)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Criar DataLoaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor) #Isso junta X e y ‚Äî tipo um par ordenado de entrada e sa√≠da: [(x‚ÇÅ, y‚ÇÅ), (x‚ÇÇ, y‚ÇÇ), ..., (xn, yn)]\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) #Divide os dados em mini-lotes de 32 amostras (ao inv√©s de passar tudo de uma vez)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)  #Embaralha os dados antes de cada √©poca de treino (shuffle=True), o que ajuda o modelo a generalizar melhor"
      ],
      "metadata": {
        "id": "xRiUZqiKVfvp"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß† Etapa 6.1: Criar o modelo de Regress√£o Log√≠stica\n",
        "Usamos o nn.Module do PyTorch para definir o modelo. Ele vai ter:\n",
        "\n",
        "Uma √∫nica camada linear (porque √© um problema de classifica√ß√£o bin√°ria)\n",
        "\n",
        "Uma fun√ß√£o sigmoide pra gerar probabilidades\n",
        "\n",
        "##üß† MAS O que √© Regress√£o Log√≠stica?\n",
        "Apesar do nome ‚Äúregress√£o‚Äù, ela √© um modelo de classifica√ß√£o, mais especificamente de classifica√ß√£o bin√°ria.\n",
        "\n",
        "##üëâ Problemas t√≠picos que ela resolve:\n",
        "Essa pessoa tem Alzheimer ou n√£o?\n",
        "\n",
        "Esse cliente vai cancelar a assinatura ou n√£o?\n",
        "\n",
        "Esse e-mail √© spam ou n√£o?\n",
        "\n",
        "Ou seja, a sa√≠da final √© sempre 0 ou 1.\n",
        "\n",
        "##üî¢ Mas por que ‚Äúlog√≠stica‚Äù?\n",
        "Porque o modelo usa a fun√ß√£o log√≠stica (tamb√©m conhecida como sigmoide) para transformar a sa√≠da da equa√ß√£o linear em uma probabilidade entre 0 e 1.\n",
        "\n",
        "Vamos imaginar passo a passo:\n",
        "üì• Voc√™ tem v√°rias vari√°veis de entrada (ex: idade, IMC, estresse etc.)\n",
        "\n",
        "üßÆ O modelo faz uma soma ponderada com pesos:\n",
        "\n",
        "        z = w1x1 + w2x2 + .... + b\n",
        "\n",
        "‚û°Ô∏è Essa soma (que pode ser qualquer n√∫mero, tipo -5 ou +8) √© passada por uma fun√ß√£o sigmoide:\n",
        "\n",
        "        sigmoid(z)= (FORMULA DA SIGMOIDE)\n",
        "          \n",
        "\n",
        "üéØ O resultado vira uma probabilidade entre 0 e 1.\n",
        "\n",
        "‚úÖ Se for maior que 0.5 ‚Üí modelo diz ‚Äú√© 1‚Äù (tem Alzheimer) ‚ùå Se for menor que 0.5 ‚Üí modelo diz ‚Äú√© 0‚Äù (n√£o tem)\n",
        "\n",
        "##üß™ Exemplo pr√°tico:\n",
        "Imagina esse caso:\n",
        "\n",
        "    Idade = 80\n",
        "    IMC = 30.5\n",
        "    Hist√≥rico familiar = Sim\n",
        "\n",
        "Se o modelo calcular:\n",
        "\n",
        "    z = 3.0\n",
        "    sigmoid(z) ‚âà 0.95\n",
        "\n",
        "Isso significa: \"95% de chance de ter Alzheimer\"\n",
        "‚Üí Modelo classifica como 1 (tem Alzheimer)\n",
        "\n",
        "Etapa\tO que acontece\n",
        "Entrada (X)\tIdade, IMC, etc.\n",
        "\n",
        "Soma linear\tz = wX + b\n",
        "\n",
        "Fun√ß√£o log√≠stica\tsigmoid(z) vira probabilidade\n",
        "\n",
        "Classifica√ß√£o\tprob > 0.5 ‚Üí classe 1, sen√£o classe 0"
      ],
      "metadata": {
        "id": "yrv8KkCcV23U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LogisticRegressionModel(nn.Module): #Definindo a estrutura do modelo. nn.Module √© s√≥ a \"base\" do PyTorch pra todos os modelos. Ele te d√° v√°rias fun√ß√µes √∫teis por tr√°s dos panos.\n",
        "    def __init__(self, input_dim): #Esse √© o construtor da classe. Ele recebe input_dim = n√∫mero de entradas do modelo (n√∫mero de colunas do seu dataset).\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1) #Aqui voc√™ cria a camada linear:  z=w1x1+w2x2+...+b  input_dim: n√∫mero de vari√°veis de entrada (ex: idade, estresse, IMC...) e o 1 √© porque voc√™ quer uma √∫nica sa√≠da (probabilidade de ter Alzheimer)\n",
        "        self.sigmoid = nn.Sigmoid() #Essa √© a fun√ß√£o log√≠stica (sigmoide), que vai transformar a sa√≠da do z (que pode ser qualquer n√∫mero) em uma probabilidade entre 0 e 1.\n",
        "\n",
        "    def forward(self, x):  #Essa fun√ß√£o diz como os dados passam pelo modelo.\n",
        "        out = self.linear(x)  #Aplicar a camada linear\n",
        "        out = self.sigmoid(out) #Aplicar a sigmoide\n",
        "        return out\n",
        "\n",
        "# Instanciar o modelo\n",
        "input_dim = X_train.shape[1] #Aqui voc√™ calcula quantas features seu modelo vai receber (quantas colunas tem no X_train)\n",
        "model = LogisticRegressionModel(input_dim) #Aqui voc√™ instancia o modelo com o n√∫mero certo de entradas."
      ],
      "metadata": {
        "id": "Bzng0e6FV4Ua"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚öôÔ∏è Etapa 6.2: Fun√ß√£o de perda e otimizador\n",
        "Como estamos fazendo classifica√ß√£o bin√°ria, vamos usar a fun√ß√£o de perda BCELoss (Binary Cross Entropy) e o otimizador SGD (gradiente descendente estoc√°stico).\n",
        "\n",
        "##üéØ Primeira coisa: O que √© uma fun√ß√£o de perda (loss function)?\n",
        "A fun√ß√£o de perda √© uma maneira de medir o erro do modelo.\n",
        "\n",
        "Ou seja:\n",
        "\n",
        "Depois de uma previs√£o, quanto o modelo errou em rela√ß√£o ao valor real?\n",
        "\n",
        "Se ele acertou ‚Üí perda pequena (quase zero)\n",
        "\n",
        "Se ele errou feio ‚Üí perda grande\n",
        "\n",
        "A perda √© usada para orientar o modelo sobre como ajustar os pesos (o \"w\" e \"b\") e melhorar nas pr√≥ximas tentativas.\n",
        "\n",
        "##üìè O que √© BCELoss (Binary Cross Entropy)?\n",
        "Como estamos em classifica√ß√£o bin√°ria (Alzheimer ou n√£o Alzheimer), a fun√ß√£o de perda adequada √© a Entropia Cruzada Bin√°ria.\n",
        "\n",
        "A f√≥rmula dela √©:\n",
        "\n",
        "       BCELoss=‚àí[y‚ãÖlog(p)+(1‚àíy)‚ãÖlog(1‚àíp)]\n",
        "\n",
        "Onde:\n",
        "\n",
        "y √© o valor real (0 ou 1)\n",
        "p √© a probabilidade prevista (entre 0 e 1)\n",
        "\n",
        "##üí° Intui√ß√£o simples:\n",
        "Se o valor real √© 1 e o modelo previu uma probabilidade perto de 1 ‚Üí perda pequena (bom!)\n",
        "\n",
        "Se o valor real √© 0 e o modelo previu uma probabilidade perto de 0 ‚Üí perda pequena (bom!)\n",
        "\n",
        "Se o valor real √© 1 e o modelo previu 0.1 ‚Üí perda grande (ruim!)\n",
        "\n",
        "Se o valor real √© 0 e o modelo previu 0.9 ‚Üí perda grande (ruim!)\n",
        "\n",
        "##üî• E o que √© o otimizador?\n",
        "O otimizador √© o \"mecanismo\" que ajusta os pesos do modelo para minimizar a perda.\n",
        "\n",
        "Ele responde:\n",
        "\n",
        "\"Beleza, o modelo errou, agora como ajustamos os pesos para errar menos?\"\n",
        "\n",
        "##‚öôÔ∏è O que √© SGD (Stochastic Gradient Descent)?\n",
        "SGD √© o otimizador mais simples e cl√°ssico:\n",
        "\n",
        "Ele calcula o gradiente (a dire√ß√£o onde a perda diminui mais r√°pido)\n",
        "\n",
        "D√° pequenos passos nessa dire√ß√£o para ajustar os pesos\n",
        "\n",
        "\"Stochastic\" porque ele atualiza usando pequenos grupos de dados (batches) em vez do dataset inteiro"
      ],
      "metadata": {
        "id": "tHkkj9vJPdsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Fun√ß√£o de perda\n",
        "criterion = nn.BCELoss() #criterion √© a fun√ß√£o que vai calcular quanto o modelo errou para cada previs√£o.\n",
        "\n",
        "# Otimizador\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01) #optimizer √© quem ajusta os pesos do modelo para tentar reduzir o erro.\n",
        "                                                    #model.parameters(): passa todos os pesos e bias do seu modelo\n",
        "                                                    #lr=0.01: √© a learning rate (taxa de aprendizado) ‚Üí controla o tamanho dos passos na atualiza√ß√£o\n",
        "\n"
      ],
      "metadata": {
        "id": "ITtksJjHPiuD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîÅ Etapa 6.3: Treinar o modelo\n",
        "Vamos iterar sobre os dados por algumas √©pocas, calcular a perda (loss), fazer a retropropaga√ß√£o e atualizar os pesos. Aqui est√° um c√≥digo simples para isso:\n",
        "\n",
        "##üî• Qual √© a ideia geral aqui?\n",
        "Treinar o modelo significa:\n",
        "\n",
        "\"Mostre exemplos pro modelo ‚Üí veja o quanto ele erra ‚Üí ajuste os pesos pra errar menos ‚Üí repita esse ciclo v√°rias vezes.\"\n",
        "\n",
        "Esse processo de repeti√ß√£o chama-se √âPOCAS."
      ],
      "metadata": {
        "id": "cZQ9bfUUPuUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "n_epochs = 100 #N√∫mero de √©pocas definido como 100, onde 1 √©poca = o modelo viu todo o conjunto de treino 1 vez.\n",
        "\n",
        "for epoch in range(n_epochs): #Faz o processo de treino 100 vezes (ou o n√∫mero que voc√™ definiu em n_epochs).\n",
        "    model.train() # Colocar o modelo em modo treinamento (√© importante pra coisas como Dropout ou BatchNorm, se existirem no modelo).\n",
        "    running_loss = 0.0 #Inicializar o erro acumulado da √©poca, Come√ßa a loss da √©poca em 0, e vai somando ao longo da √©poca.\n",
        "\n",
        "    for inputs, labels in train_loader: #Pegar mini-lotes do treino. Cada inputs tem um pequeno peda√ßo dos dados (batch), e labels s√£o os r√≥tulos correspondentes (0 ou 1).\n",
        "\n",
        "        # Zerar os gradientes anteriores\n",
        "        optimizer.zero_grad() #No PyTorch, os gradientes s√£o acumulativos por padr√£o, ent√£o sempre zeramos\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs) #Faz a previs√£o para esse mini-lote de dados.\n",
        "\n",
        "        # Calcular perda\n",
        "        loss = criterion(outputs, labels) #Compara a previs√£o (outputs) com o valor real (labels) usando a fun√ß√£o BCELoss.\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward() #Calcula o gradiente da perda em rela√ß√£o aos pesos ‚Äî ou seja, quanto e para onde cada peso deveria mudar pra reduzir o erro.\n",
        "\n",
        "        # Atualizar pesos\n",
        "        optimizer.step() # Usa o otimizador (SGD) pra atualizar os pesos usando os gradientes calculados.\n",
        "\n",
        "        running_loss += loss.item() #Vai somando a perda de cada mini-lote pra calcular a perda m√©dia da √©poca.\n",
        "\n",
        "    # Mostrar a loss m√©dia da √©poca\n",
        "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
        "        print(f\"√âpoca {epoch+1}/{n_epochs}, Loss: {running_loss/len(train_loader):.4f}\") # A cada 10 √©pocas (e na primeira), imprime a perda m√©dia.\n",
        "                                                                                         #Assim voc√™ acompanha se o modelo est√° melhorando (a perda deve diminuir).\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEJ9IcfDPv4o",
        "outputId": "7d4efe6a-b9f9-4bd4-ce95-cf1e0f037e95"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "√âpoca 1/100, Loss: 0.3767\n",
            "√âpoca 10/100, Loss: 0.3732\n",
            "√âpoca 20/100, Loss: 0.3694\n",
            "√âpoca 30/100, Loss: 0.3677\n",
            "√âpoca 40/100, Loss: 0.3672\n",
            "√âpoca 50/100, Loss: 0.3661\n",
            "√âpoca 60/100, Loss: 0.3653\n",
            "√âpoca 70/100, Loss: 0.3650\n",
            "√âpoca 80/100, Loss: 0.3660\n",
            "√âpoca 90/100, Loss: 0.3643\n",
            "√âpoca 100/100, Loss: 0.3650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#üìä Etapa 7: Avaliar o modelo\n",
        "Agora vamos ver como ele se saiu nos dados de teste. A gente vai calcular:\n",
        "\n",
        "Acur√°cia\n",
        "\n",
        "Precis√£o\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-score\n",
        "\n",
        "E tamb√©m uma matriz de confus√£o\n",
        "\n",
        "\n",
        "##üéØ O que √© \"avaliar o modelo\"?\n",
        "Depois que o modelo foi treinado, a gente quer saber:\n",
        "\n",
        "Ele √© bom ou ruim?\n",
        "\n",
        "Ele acerta bastante?\n",
        "\n",
        "Quando erra, como ele erra?\n",
        "\n",
        "Pra responder isso, usamos m√©tricas de avalia√ß√£o.\n",
        "N√£o basta s√≥ olhar se a loss ficou pequena no treino ‚Äî a gente precisa ver como o modelo se comporta com dados novos (teste).\n",
        "\n",
        "##üìè As 4 m√©tricas que voc√™ est√° calculando:\n",
        "1Ô∏è‚É£ Acur√°cia\n",
        "Propor√ß√£o de vezes que o modelo acertou, considerando todos os casos.\n",
        "\n",
        "F√≥rmula:\n",
        "\n",
        "        acuracia = Total de acertos / total de previs√µes\n",
        "\n",
        "üîµ Exemplo:\n",
        "\n",
        "Voc√™ previu 80 casos corretamente de 100 ‚Üí 80% de acur√°cia.\n",
        "\n",
        "üß† Cuidado: se os dados tiverem muito mais \"n√£o doente\" que \"doente\", a acur√°cia pode ser enganosa!\n",
        "\n",
        "##2Ô∏è‚É£ Precis√£o\n",
        "Das vezes que o modelo disse \"tem Alzheimer\", quantas vezes ele estava certo?\n",
        "\n",
        "F√≥rmula:\n",
        "\n",
        "        precis√£o = verdadeiros positivos / (verdadeiros positivos + falsos positivos)\n",
        "‚Äã\n",
        "\n",
        "üîµ Exemplo:\n",
        "\n",
        "O modelo previu \"Alzheimer\" para 10 pessoas, mas s√≥ 7 realmente tinham ‚Üí Precis√£o = 70%.\n",
        "\n",
        "üß† Import√¢ncia: boa quando voc√™ quer evitar falsos alarmes (n√£o acusar doen√ßa onde n√£o tem).\n",
        "\n",
        "##3Ô∏è‚É£ Recall\n",
        "Das pessoas que realmente tinham Alzheimer, quantas o modelo conseguiu encontrar?\n",
        "\n",
        "F√≥rmula:\n",
        "\n",
        "      Recall = verdadeiros positivos / (verdadeiros positivos + falsos negativos)\n",
        "\n",
        "üîµ Exemplo:\n",
        "\n",
        "Existem 100 doentes, mas o modelo s√≥ detectou 80 ‚Üí Recall = 80%.\n",
        "\n",
        "üß† Import√¢ncia: boa quando voc√™ n√£o quer deixar passar casos reais (evitar esquecer de diagnosticar quem precisa).\n",
        "\n",
        "##4Ô∏è‚É£ F1-Score\n",
        "Uma m√©dia equilibrada entre Precis√£o e Recall.\n",
        "\n",
        "F√≥rmula:\n",
        "\n",
        "      F1 = 2 * ((precis√£o * recall)/(presis√£o + recall))\n",
        "\n",
        "üîµ Exemplo:\n",
        "\n",
        "Se Precis√£o = 70% e Recall = 80%, o F1 vai ficar entre eles (tipo 74%).\n",
        "\n",
        "üß† Import√¢ncia: √∫til quando os dados est√£o desbalanceados e voc√™ quer equilibrar o foco entre acertar positivos e lembrar de todos.\n",
        "\n",
        "##üß© E a Matriz de Confus√£o?\n",
        "Essa √© uma tabela que mostra exatamente onde o modelo acertou e onde errou:\n",
        "\n",
        "TN: acertou que n√£o tinha Alzheimer\n",
        "\n",
        "TP: acertou que tinha Alzheimer\n",
        "\n",
        "FP: disse que tinha Alzheimer, mas n√£o tinha\n",
        "\n",
        "FN: disse que n√£o tinha Alzheimer, mas tinha\n",
        "\n",
        "üß† Um exemplo pequeno de tudo isso junto:\n",
        "Imagine 10 pacientes:\n",
        "\n",
        "6 n√£o t√™m Alzheimer\n",
        "\n",
        "4 t√™m Alzheimer\n",
        "\n",
        "E o modelo previu:\n",
        "\n",
        "\n",
        "          Paciente\tReal\tPredito\n",
        "          1\t         0\t     0\n",
        "          2\t         0\t     0\n",
        "          3        \t 0\t     1\n",
        "          4\t         0\t     0\n",
        "          5\t         0\t     0\n",
        "          6\t         0\t     0\n",
        "          7\t         1\t     1\n",
        "          8\t         1\t     1\n",
        "          9\t         1\t     0\n",
        "          10\t        1\t     1\n",
        "\n",
        "Ent√£o:\n",
        "\n",
        "TN = 5 (5 acertos de \"n√£o tem\")\n",
        "\n",
        "FP = 1 (falso positivo)\n",
        "\n",
        "TP = 3 (acertos de \"tem\")\n",
        "\n",
        "FN = 1 (falso negativo)\n",
        "\n",
        "A√≠:\n",
        "\n",
        "Acur√°cia = (5 + 3) / 10 = 80%\n",
        "\n",
        "Precis√£o = 3 / (3 + 1) = 75%\n",
        "\n",
        "Recall = 3 / (3 + 1) = 75%\n",
        "\n",
        "F1-score ‚âà 75%\n"
      ],
      "metadata": {
        "id": "2xbKGdOgTFBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìå C√≥digo para avalia√ß√£o:"
      ],
      "metadata": {
        "id": "eS2pLMeOTIfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fun√ß√µes da biblioteca sklearn para calcular as m√©tricas (acur√°cia, precis√£o, recall, F1, matriz de confus√£o).\n",
        "#numpy para poder manipular arrays (porque sklearn trabalha com numpy, e n√£o com tensores do PyTorch).\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix #\n",
        "import numpy as np\n",
        "\n",
        "# Colocar o modelo em modo avalia√ß√£o\n",
        "model.eval()  #Quando voc√™ chama model.eval(), voc√™ diz: \"Modelo, agora voc√™ n√£o precisa mais treinar, s√≥ prever! \"\n",
        "\n",
        "# Fazer previs√µes no conjunto de teste\n",
        "with torch.no_grad(): #Desligar o c√°lculo de gradientes, Isso economiza mem√≥ria e acelera a execu√ß√£o. Al√©m de que n√£o faz sentido calcular o gradiente na avalia√ß√£o\n",
        "    y_pred_probs = model(X_test_tensor) #Voc√™ manda o X_test_tensor (seus dados de teste) pro modelo. O modelo responde com probabilidades de cada exemplo ser 1 (Alzheimer).\n",
        "    y_pred = (y_pred_probs >= 0.5).float() #Transformar probabilidades em 0 ou 1, Se a probabilidade for maior ou igual a 0.5, a previs√£o √© 1 (Alzheimer).\n",
        "                                           #Se for menor que 0.5, a previs√£o √© 0 (N√£o tem Alzheimer).\n",
        "\n",
        "# Converter para numpy, pois sklearn exige que as entradas sejam arrays NumPy.\n",
        "y_true_np = y_test_tensor.numpy() #transforma as respostas reais (y_test_tensor)em NumPy Arrays.\n",
        "y_pred_np = y_pred.numpy() #transforma as respostas previstas (y_pred) em NumPy Arrays.\n",
        "\n",
        "# Calcular m√©tricas\n",
        "acc = accuracy_score(y_true_np, y_pred_np)   #Percentual de acertos totais\n",
        "prec = precision_score(y_true_np, y_pred_np) #Das vezes que o modelo disse que era Alzheimer, quantas vezes estava certo\n",
        "rec = recall_score(y_true_np, y_pred_np)     #Das pessoas que realmente tinham Alzheimer, quantas o modelo detectou\n",
        "f1 = f1_score(y_true_np, y_pred_np)          #M√©dia harm√¥nica entre precis√£o e recall (equil√≠brio)\n",
        "cm = confusion_matrix(y_true_np, y_pred_np)  #Matriz que mostra os acertos e erros divididos por tipo\n",
        "\n",
        "print(f\"Acur√°cia: {acc:.4f}\")\n",
        "print(f\"Precis√£o: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"Matriz de Confus√£o:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLNd6nA7TJ8o",
        "outputId": "0865b3df-72c2-42fb-a474-8c2a7eaf1fb6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acur√°cia: 0.8302\n",
            "Precis√£o: 0.7899\n",
            "Recall: 0.7124\n",
            "F1-Score: 0.7491\n",
            "Matriz de Confus√£o:\n",
            "[[248  29]\n",
            " [ 44 109]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úÖ Acur√°cia: 83,0%\n",
        "O modelo acerta 83,0% dos casos totais ‚Äî isso inclui quem tem e quem n√£o tem Alzheimer.\n",
        "\n",
        "‚ö†Ô∏è Lembre-se: se as classes forem desbalanceadas (muito mais casos de um lado), a acur√°cia sozinha pode ser um pouco enganosa.\n",
        "\n",
        "##üìç Precis√£o: 78,9%\n",
        "Das pessoas que o modelo previu que t√™m Alzheimer, 78,9% realmente t√™m.\n",
        "\n",
        "Alta precis√£o √© importante quando queremos evitar falsos positivos ‚Äî ou seja, n√£o acusar algu√©m de ter Alzheimer quando na verdade n√£o tem.\n",
        "\n",
        "\n",
        "##üìç Recall: 71,2%\n",
        "Das pessoas que realmente t√™m Alzheimer, o modelo conseguiu identificar 71,2% delas.\n",
        "\n",
        "Alto recall √© importante para n√£o deixar passar casos verdadeiros ‚Äî queremos identificar o m√°ximo poss√≠vel de pacientes que realmente t√™m a doen√ßa.\n",
        "\n",
        "##üìç F1-Score: 74,9%\n",
        "O F1-score √© a m√©dia equilibrada entre precis√£o e recall.\n",
        "Indica que o modelo tem um bom equil√≠brio: ele √© razoavelmente bom tanto em acertar quem tem quanto em n√£o errar quem n√£o tem.\n",
        "\n",
        "##üßÆ Matriz de Confus√£o:\n",
        "Verdadeiros Negativos (TN): 248 ‚Üí pessoas sem Alzheimer que foram corretamente classificadas como \"n√£o t√™m\".\n",
        "\n",
        "Falsos Positivos (FP): 29 ‚Üí pessoas sem Alzheimer que o modelo disse que t√™m (erro de \"falso alarme\").\n",
        "\n",
        "Falsos Negativos (FN): 44 ‚Üí pessoas com Alzheimer que o modelo n√£o conseguiu detectar (erro preocupante).\n",
        "\n",
        "Verdadeiros Positivos (TP): 109 ‚Üí pessoas com Alzheimer corretamente identificadas."
      ],
      "metadata": {
        "id": "EQVw2A71TTmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üéØ 1. Matriz de Confus√£o Visual"
      ],
      "metadata": {
        "id": "lle55W2aVOpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Sem Alzheimer\", \"Com Alzheimer\"], yticklabels=[\"Sem Alzheimer\", \"Com Alzheimer\"])\n",
        "plt.xlabel(\"Predi√ß√£o\")\n",
        "plt.ylabel(\"Valor Real\")\n",
        "plt.title(\"Matriz de Confus√£o\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "pBXdvzdSVJH0",
        "outputId": "9cd63a27-bb6f-4ea2-8c2f-270f231b867e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}